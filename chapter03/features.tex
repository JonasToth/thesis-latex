\subsection{Keypoint Detection and Feature Description}

Extracting information from images is a common task in computer vision.
One approach is the detection of salient regions of special interest --- \emph{features}.
Such regions can have arbitrary detectable properties, like a sharp brightness gradient or being corner-like.
Detecting such a region results in a \emph{keypoint} that might have properties like a \emph{size}, \emph{response} and sometimes even an \emph{orientation} (Figure~\ref{fig:features_example}).
\begin{figure}[H]
    \scalebox{0.95}{%
    \input{chapter03/img/features.tex}
    }
    \caption[Schematic feature detection and matching]{\emph{Schematic feature detection and matching.} This figure displays two polygons from different view points. The feature detection algorithm detects the corners of the polygon as keypoints in both images. The order of detection is not stable and establishing the correspondence between the detected keypoints requires further processing. A feature descriptor examines to local neighbourhood of each keypoint, visualized with the red dotted square. This descriptor is then used to find the most similar region around a keypoint of the other image. This process is called \emph{feature matching}.}\label{fig:features_example}
\end{figure}
Keypoints on itself are not descriptive enough to be identified in different images.
A changing view point or even a different camera result in changes to the overall shape and appearance of the scene.
Reliable keypoint identification requires the analysis of bigger image patches.
The \emph{keypoint descriptor} analyzes a predefined region around the centered keypoint and extracts a vector for that region.
Different aspects can be analyzed and Section~\ref{sec:feature_algorithms} introduces the most common algorithms for that task.
The extracted vector has a high dimension with tens to hundreds of elements.

Connecting the keypoints between different images uses the extracted descriptors for each keypoint.
\emph{Similar} descriptors are associated.
Similarity of the descriptors is calculated with a matching norm depdendent on the structure of the descriptor.
Dense real descriptors commonly use the Euclidean norm where as binary descriptors use the hamming norm.
Additional constraints, like geometric consistency, improve the accuracy of the matching result.
For the provided example this result might be
\begin{equation}
\begin{aligned}
    \mathbf{K_{1,2}} &\leftrightarrow \mathbf{K_{2,2}}~\textcolor{darkgreen}{\bullet} &
    \mathbf{K_{1,4}} &\leftrightarrow \mathbf{K_{2,5}}~\textcolor{darkgreen}{\bullet} &
    \mathbf{K_{1,5}} &\leftrightarrow \mathbf{K_{2,3}}~\textcolor{darkgreen}{\bullet} \\
    \mathbf{K_{1,3}} &\leftrightarrow \mathbf{K_{2,4}} &
    \mathbf{K_{1,1}} &\leftrightarrow \mathbf{K_{2,1}} &
\end{aligned}
\end{equation}
with green bullets indicating a correct match.
An important descriptor design criteria is the trade-off between computational cost and descriptive power, as especially descriptor matching is computationally expensive.

Features play a key role in multiple computer vision tasks.
Place or object recognition and document searching rely on the identification of similar descriptors in queried image to already indexed descriptors of known images.
Typically, storage and computational constrains require preprocessing the descriptors with clustering techniques to reduce the number of descriptors to store and allow hierarchical matching.

The second major application is visual odometry and \gls{sfm}.
Corresponding keypoints provide landmarks for triangulation and pose reconstruction.
The relative pose between the two camera is computed with Nist√©r's 5-point algorithm\cite{nister_ieee2004}.
To obtain a stable and consistent result for the pose the \acrshort{RANSAC} (\acrlong{RANSAC})\cite{fischler_ransac_1980} algorithm performs multiple pose computations with random subsets of keypoint correspondences.
The assumed pose is used to project the keypoints from one image into the other.
A high pixel distance for the projected keypoints to the expected keypoints indicates a wrong pose, showing that the used subset of keypoints for the pose calculation had false matches.
After multiple iterations, a consensus pose might be obtained and can be optimized as final pose.
If no such consensus pose exists, the image pair is rejected.

Establishing the correspondence between keypoints of multiple images can be supported by using additional heuristics for descriptor matching.
The first heuristic is \emph{cross checking}.
Descriptors correspond only if the distance of the descriptors is minimal in both directions.
The second commonly used heuristic is \emph{Lowe's ratio check}\cite{lowe_ijcv04} putting the best and second best descriptor match distance into relation and requiring a certain distance ratio to be superseded.
The last simple heuristic is the definition of an \emph{upper bound} for the match distance.
Improvements to \acrshort{RANSAC}\cite{sattler_iccv2009,chum_cvpr2005} use more sophisticated keypoint sampling criteria by exploiting spatial consistency or the descriptor distance.

More complicated keypoint preprocessing can be done to reduce the number of descriptors to match.
Keypoints can be discarded to achieve a higher spread over the image and avoid clusters of keypoints that provoke descriptor ambiguity.
The detector response is another important criteria for sorting keypoints by quality.
If apriori information of the approximate motion of the camera is known matches can be ranked based on the expected displacement of the keypoint.
