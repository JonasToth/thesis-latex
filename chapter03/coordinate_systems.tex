\subsection{Coordinate Systems}

This section introduces the used coordinates systems and naming conventions that model the sensory system commonly used in computer vision.
Additionally, homogeneous coordinates allow efficient computation of rotation and translation with one matrix-vector multiplication and knowledge of it is a prerequisite.
Both~\cite{hartley_2004} and~\cite{corke_2011} provide excellent coverage of these topics.

\subsubsection*{Naming Conventions}

A point in space is referenced by a vector in that space.
The global reference frame is arbitrarily choosen in \emph{world coordinates}.
Within that world coordinate system exist one or more sensors spanning their own coordinate system.
Referencing the point relative to such a sensor yields \emph{camera coordinates}.
The sensor itself performs some form of dimension reducing projection of the three dimensional point to a two dimensional point, an \emph{image coordinate}.
\emph{Image coordinates} are an intermediate representation before discretizing the point to individual pixels, called \emph{pixel coordinates}.
Inverting this projection results in \emph{spherical coordinates}, camera coordinates with unit length that just encode the direction of a light ray that hits a pixel.
Different sensor models describe these projecting transformations mathematically.
Note, that the relative transformation between \emph{camera coordiantes} and \emph{world coordinates}, the sensors \emph{pose}, can change over time.
Multiple sensors can exist within the \emph{world coordinate system}.

\subsubsection*{Coordinate Transformations and Pose}

\begin{figure}[H]
    \scalebox{0.7}{%
    \input{chapter03/img/coordinate_transformation}
    }
    \caption[Coordinate transformation]{\emph{Coordinate transformation.} Relationship between different representation of the same point in different coordinate systems. The relationship displayed here and the corresponding linear algebra holds true for cartesian coordinate systems of any dimension.}
\end{figure}

Let $\mathbf{O_\mathcal{W}}$ be the origin of the \emph{world coordinate system}.
A three dimensional vector $\vec{P_\mathcal{W}} = \rowvecxxx{U}{V}{W}$ represents a point in this room relative to the origin $\mathbf{O_\mathcal{W}}$.
Seeing this point $\mathbf{P_\mathcal{W}}$ from a camera $\mathbf{C_\mathcal{W}}$ within the same room is equivalent to changing the coordinate system from \emph{world coordinates} to \emph{camera coordinates} of that sensor.
The relative rotation and translation of the camera $\mathbf{C_\mathcal{W}}$ to the room is also called its \emph{pose}.
It is parametrized by a rotation matrix $R$ and a translation vector $\vec{t}$.
Homogeneous coordinates provide a computational more efficient way to apply the transformation to vectors by $4 \times 4$ matrix-vector multiplication instead of $3 \times 3$ matrix-vector multiplication and an additional $3 \times 1$ vector addition.
The point $\mathbf{P_\mathcal{W}}$ seen from the camera $\mathbf{C_\mathcal{W}}$ is computed with the homogeneous transformation matrix $H = \begin{bmatrix} R & \vec{t} \\
    \begin{matrix}0 & 0 & 0\end{matrix} & 1 \end{bmatrix}$.
\begin{equation}
\begin{aligned}
    \colvech{X}{Y}{Z}&= \begin{pmatrix}
        r_{11} & r_{12} & r_{13} & t_x \\
        r_{21} & r_{22} & r_{23} & t_y \\
        r_{31} & r_{32} & r_{33} & t_z \\
        0      & 0      & 0      & 1 \\
    \end{pmatrix} \colvech{U}{V}{W} \\
    \vec{P_\mathcal{C}} &= H \vec{P_\mathcal{W}}
\end{aligned}
\end{equation}
Coordinate transformations do not loose information.
