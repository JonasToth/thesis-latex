\subsection{Coordinate Systems}

This section introduces the used coordinates systems and naming conventions that model the sensory system.
These conventions are commonly used in computer vision.
Additionally, homogeneous coordinates allow efficient computation of rotation and translation with one matrix-vector multiplication and knowledge of it is a prerequisite.
Both~\cite{hartley_2004} and~\cite{corke_2011} provide excellent coverage of these topics.

\subsubsection*{Naming Conventions}

A point in space is referenced by a vector in that space.
The global is described in \emph{world coordinates} and is arbitrarily defined.
Within that world coordinate system exists one or more sensors spanning their own coordinate system.
Referencing the point relative to such a system yields \emph{camera coordinates}.
The sensor itself performs some form of dimension reducing projection of the three dimensional point to a two dimensional point, an \emph{image coordinate}.
\emph{Image coordinates} are an intermediate representation before discretizing the point to individual pixels, called \emph{pixel coordinates}.
Different sensor models describe these conceptual transformations mathematically.
Note, that the relative transformation between \emph{camera coordiantes} and \emph{world coordinates} can change over time or multiple sensors can exist within the \emph{world coordinate system}.

\subsubsection*{Coordinate Transformations and Pose}

\begin{figure}[H]
    \input{chapter03/img/coordinate_transformation}
    \caption[Coordinate Transformation]{Relationship between different representation of the same point in different coordinate systems. The relationship displayed here and the corresponding linear algebra holds true for cartesian coordinate systems of any dimension.}
\end{figure}

Let $\mathbf{O}$ be the origin of the \emph{world coordinate system}.
A three dimensional vector $\vec{P} = \rowvecxxx{U}{V}{W}$ represents a point in this room relative to the origin $\mathbf{O}$.
Seeing this point $\mathbf{P}$ from a camera $\mathbf{C}$ within the same room is equivalent to changing the coordinate system from \emph{world coordinates} to \emph{camera coordinates} of that sensor.
The relative rotation and translation of the camera $\mathbf{C}$ to the room is also called its \emph{pose}.
It is parametrized by a rotation matrix $R$ and a translation vector $\vec{t}$.
Homogeneous coordinates provide a computational more efficient way to apply the transformation to vectors by $4 \times 4$ matrix-vector multiplication instead of $3 \times 3$ matrix-vector multiplication and an additional $3 \times 1$ vector addition.
The point $\mathbf{P}$ seen from the camera $\mathbf{C}$ is computed with the homogeneous transformation matrix $H = \begin{bmatrix} R & \vec{t} \\ 
    \begin{matrix}0 & 0 & 0\end{matrix} & 1 \end{bmatrix}$.
\begin{equation}
\begin{aligned}
    \colvech{X}{Y}{Z}&= \begin{pmatrix}
        r_{11} & r_{12} & r_{13} & t_x \\
        r_{21} & r_{22} & r_{23} & t_y \\
        r_{31} & r_{32} & r_{33} & t_z \\
        0      & 0      & 0      & 1 \\
    \end{pmatrix} \colvech{U}{V}{W} \\
    \vec{P}' &= H \vec{P}
\end{aligned}
\end{equation}

Coordinate transformations do not loose information.
The next section introduces \emph{projections}, that map the three dimensional points into the plane.
