\subsection{Metrics}

To determine the performance of the feature-based approach, the matching of keypoints is framed in terms of a binary classifier.
For a keypoint correspondence between two images, the classification task is to determine if those keypoints correspond to the same point in the real world or not.
The correspondence is computed based on the relative pose of consecutive images and only two consecutive images are analyzed.
The following subsections describe each component of this evaluation pipeline in more detail.

\subsubsection{Ground Truth Poses}

The dataset \emph{Mine} provides ground truth poses from a prior \gls{sfm} reconstruction.
Due to the global optimization of the \gls{sfm} algorithm, these poses do not match with the depth values of the depth images.
The other datasets do not contain a precomputed pose.
Therefore, each pose is computed and refined with an ICP algorithm, namely OpenCV's \texttt{FASTICPOdometry}\cite{opencv_library} that is based on the KinectFusion\cite{newcombe_ismar2011} work.
This relative pose serves as foundation of the evaluation and is assumed to be correct within small tolerance.
The accuracy assumption of the \texttt{FASTICPOdometry} poses is tested by manual inspection of the backprojection of obviously related keypoints and the results showed no systematic erroneous poses.

\subsubsection{Backprojection and Distance Threshold}

In two consecutive images, all keypoints are extracted with the chosen algorithm and settings.
Each keypoint of the first image $I_1$ is projected to the unit sphere, e.g. with Equation~\ref{eq:pinhole_backward}, multiplied with the range value of the corresponding pixel.
The resulting camera coordinate is transformed to the second camera coordinate system (Equation~\ref{eq:homogeneous_matrix}).
Projecting the keypoint into the second camera with the matching forward projection (e.g. Equation~\ref{eq:pinhole_forward}) finalizes the procedure, demonstrated in Figure~\ref{fig:keypoint_projection}.
This results in two sets of keypoints in the second image $I_2$, the keypoints detected in this frame and the keypoints detected in the previous frame, seen from this frame's pose.
Assuming a correct relative pose, the corresponding keypoints have a small pixel distance between each other.
\emph{Small} is a relative value and the chosen threshold in the experiments is 2\,px.
This approach can only result in a proper analysis for a sparse distribution of keypoints that actually correspond to image structure and requires small changes in pose.
When the pose difference is big, it can happen that keypoints get projected to the same position as some other valid keypoint without referencing the same world point.
Too many points create ambiguity with respect to the backprojection tolerance.
\begin{figure}[b!]
    \input{chapter05/img/backprojection}
    \caption[Backprojection of keypoints visualized]{\emph{Backprojection of keypoints visualized.} The chosen approach of projecting keypoints between frames is demonstrated in this figure. Keypoints of image $I_1$ are blue dots in both images and the orange ones are only detected in image $I_2$. Actual correspondences result in very close points in $I_2$, indicated as blue dot with orange border, whereas unrelated points show no proximity. This assumption holds for small changes in pose and relatively sparse distribution of detected keypoints.}\label{fig:keypoint_projection}
\end{figure}

First, OpenCV's \texttt{BFMatcher}\cite{opencv_library} matcher establishes correspondences based on the descriptor distance and applies crosschecking --- the descriptors must have minimal distance in both directions --- as only heuristic.
The matches are partitioned into four sets: \emph{true-positive}, \emph{false-positive}, \emph{true-negative} and \emph{false-negative} as introduced in Section~\ref{sec:statistic_classifier}.
The union of these sets are all detected keypoints.
First, the matches are analyzed for true and false positives and true correspondences are removed from further analysis. 
Let $proj$ be the keypoints from $I_1$, backprojected to $I_2$.
$kps$ are the keypoints from $I_2$, $matches$ are pairs of keypoints the matching algorithm considers as correspondences and $threshold$ is the maximum allowed backprojection error for keypoints to still be considered a true correspondence.
Algorithm~\ref{alg:false_positives} classifies all $matches$ as true or false positives.
\begin{algorithm}[H]
\setstretch{1.2}
\footnotesize
\begin{algorithmic}[0]
\Require{$\forall m \in matches \Rightarrow m.first \in proj \land m.second \in kps$}
\Require{$threshold > 0.0$}
\Ensure{$\vert true \vert + \vert false \vert = \vert matches \vert$}
    \Function{ClassifyPositives}{proj, kps, matches, threshold}
    \ForAll{$m \in matches$}
    \If{$\Call{distance}{proj[m.first], kps[m.second]} < threshold$}
        \State$true \gets true \cup m$
        \State$proj \gets proj \setminus m.first$
        \Comment{Prevent double usage}
    \Else%
        \State$false \gets false \cup m$
    \EndIf%
    \State$kps \gets kps \setminus m.second$
    \EndFor%
    \EndFunction%
\end{algorithmic}
\caption{This algorithm distinguishes between a true and a false positive match.}\label{alg:false_positives}
\end{algorithm}
After this process some keypoints detected in $I_2$ might be left to analyze for a correspondence that were not assigned during matching, the false negatives (Algorithm~\ref{alg:false_negatives}).
\begin{algorithm}[H]
\setstretch{1.2}
\footnotesize
\begin{algorithmic}
\Require{$threshold > 0.0$}
\Require{$kps_{pre-call}$ does not contain matched keypoints}
\Ensure{$\vert false\_negatives \vert + \vert true\_negatives \vert = \vert kps_{pre-call} \vert$}
    \Function{ClassifyNegatives}{proj, kps, threshold}
    \ForAll{$k \in kps$}
        \State$closest \gets \Call{FindClosestFrom}{proj, k}$
        \If{$\Call{distance}{closest, k} < threshold$}
            \State$false\_negatives \gets false\_negatives \cup (k, closest)$
            \State$proj \gets proj \setminus closest$
        \EndIf
    \EndFor%
    \State{$true\_negatives \gets kps \setminus false\_negatives$}
    \EndFunction%
\end{algorithmic}
\caption{The unmatched keypoints are classified as true or false negative.}\label{alg:false_negatives}
\end{algorithm}
To classify the negatives, each keypoint's distance from $I_2$ to the backprojected keypoints from $I_1$ is tested to be within the defined threshold.
If this is the case, both keypoints are defined as corresponding and result in a false negative. The remaining points are true negatives.
The partitioning of the keypoints allows to analyze more aspects of matches, e.g.~the descriptor distances for true and false positives.

\subsubsection{Histograms and Summary Statistics}

To visualize and understand the properties of keypoints and matches, the partitioned keypoint's are tracked in histograms.
Summary statistics reduce the statistical distributions to a few representative values.
Combining different measures, such as the measure of location, distribution and shape gives key insights.

Both histograms and its summary statistics are created for the keypoint size, keypoint response, descriptor distance between all keypoints and both descriptor distance for \emph{true-positives} and \emph{false-positives}.
The quantitative measures for each property are the \emph{minimum} and \emph{maximum} value, \emph{median} and \emph{arithmetic mean}, \emph{variance} and \emph{standard deviation} and \emph{skeweness} of the distribution.

\subsubsection{Classification Evaluation}

The analysis of the keypoint and descriptor characteristics already gives some insight into the algorithm performance but is not suitable for a comparison between different algorithms.
For this task the quality of the decisions the keypoint matching algorithm must be assessed.
The evaluation builds on the analysis of binary classifiers as introduced in Section~\ref{sec:statistic_classifier}.

The matching of descriptors is done in a simple but consistent way.
A match is defined as the closest descriptor in the other image, that also matches in the other direction, a heuristic commonly called \emph{crosschecking}.
No other criteria like a maximum matching distance is taken into account.
For each obtained confusion matrix, the ratios \emph{precision}, \emph{recall} or \emph{sensitivity}, \emph{fallout} or \emph{false alarm rate}, \emph{accuracy} or the \emph{Rand index} and \emph{Youden's index} are computed at first.
For a comparison between algorithms and configurations the results are plotted in \gls{ROC} space.
