\subsection{Metrics}

To determine the performance of the feature-based approach, the matching of keypoints is framed in terms of a binary classifier.
For a keypoint correspondence between two images the classification task is to determine if those keypoint correspond to the same point in the real world or not.
The correspondence is computed based on the relative pose of consecutive images and only 2 consecutive images are analyzed.
This evaluation is done for \Glspl{bearing-angle-image} and \Glspl{flexion-image}.
The following subsections describe each component of this evaluation pipeline in more detail.
To the best of the author's knowledge no other work approaches the evaluation of feature detectors and descriptors like this.

\subsubsection{Groundtruth Poses}

The dataset \emph{Lehrpfad} provides groundthruth poses from a prior \gls{sfm} reconstruction.
Due to the global optimization of the \gls{sfm} algorithm these poses do not match with the depth values of the depth images.
The other dataset do not contain a precomputed pose.
Each pose is computed and refined with an ICP algorithm, namely OpenCV's \emph{FASTICPOdometry} that is based on the KinectFusion\cite{newcombe_ismar2011} work.
This relative pose serves as foundation of the evaluation and is assumed to be correct within small tolerance.
The accuracy assumption of the \emph{FASTICPOdometry} poses is tested by manual inspection of the backprojection of obviously related keypoints and the results showed no systematic errornous poses.

\subsubsection{Backprojection and Distance Threshold}

In two consecutive images all keypoints are extracted with the choosen algorithm and settings.
The keypoints of the first image is projected into the view of the second images using the determined relative pose and camera model.
This gives two sets of keypoints in the second image, the keypoints detected in this frame and the keypoints detected in the previous frame, seen from this frames pose.
Assuming a correct relative pose, the corresponding keypoints have a small pixel distance between each other.
\emph{Small} is a relative value and the choosen threshold in the experiments is $2px$.
This approach can only result in a proper analysis for a sparse distribution of keypoints that actually respond to image structure and small changes in pose.
When the pose difference is big it can happen that keypoints to covered geometry get projected to the same position as some other valid keypoint.
Too many points create ambiguity with respect to the backprojection tolerance that is required due to imperfect projections of real world sensors.
\begin{figure}[H]
    \input{chapter05/img/backprojection}
    \caption{The choosen approach of projection keypoints between frames is demonstrated in this figure. Keypoints of image $I_1$ are blue dots in both images and the oranges ones are only detected in image $I_2$. Actual correspondences result in very close points in $I_2$, indicated as blue dot with orange border, whereas unrelated points show no proximity. This assumption holds for small changes in pose and relativly sparse distribution of detected keypoints.}
\end{figure}
The analysis of the descriptor performance requires the matching step first, that establishes the correspondences of the matcher.
To classify the result of the descriptor matching, each keypoint needs to be analyzed further.
The result are four sets: \emph{true-positive}, \emph{false-positive}, \emph{true-negative} and \emph{false-negative} as introduced in Section~\ref{sec:staticstics_classifier}.
The union of these sets are all detected keypoints.

Partitioning the keypoints is done with the following steps.
First the matches are analyzed for true and false positives and true correspondences removed from further analysis. 
\begin{algorithm}
\begin{algorithmic}[0]
    \Comment{\emph{proj} are the backprojected keypoints from $I_1$ and \emph{kps} the keypoints from $I_2$}
    \Function{ClassifyPositives}{proj, kps, matches, threshold}
    \ForAll{m in matches}
    \If{distance(proj[m.first], kps[m.second]) < threshold}
        \State $true \gets true \cup m$
        \Comment{Ensure no double usage of a keypoint in image2}
        \State $kps \gets kps \setminus m.second$
    \Else%
        \State $false \gets false \cup m$
    \EndIf%
    \EndFor%
    \Ensures{\vert true \vert + \vert false \vert = \vert matches \vert}
    \EndFunction%
\end{algorithmic}
\caption{This listing describes the essence of distinguishing between a true and a false positive match.}
\end{algorithm}
After this process some keypoints detected in $I_2$ might be left to analyze for a correspondence that was not assigned during matching, the false negatives.
\begin{algorithmic}
    \Comment{\emph{proj} are the backprojected keypoints from $I_1$ and \emph{kps} the keypoints from $I_2$ left after removing the true positives}
    \Function{DetectFalseNegatives}{proj, kps, threshold}
    \ForAll{k in kps}
        
    \EndFor%
    \EndFunction%
    \caption{This listing describes the essence of distinguishing between a true and a false positive match.}
\end{algorithmic}

\begin{enumerate}
    \item false negatives are searched in the remaining query-indices, using the same distance threshold
    \item every unhandled keypoint is a \emph{true-negative} as there are no corresponding keypoints left
\end{enumerate}

\subsubsection{Histograms and Summary Statistics}

To understand the characteristics of a quantity a common approach is to create a histogram.
The histograms counts frequencies for a specific range of data.

Summary statistics are used to reduce a statistical distribution to a few representative values.
Different measures are used, such as the measure of location, distribution and shape.
Those values help to understand and compare different setups and configurations.

Both histograms and its summary statistics are created for the keypoint size, keypoint response, descriptor distance between all keypoints and both descriptor distance for \emph{true-positives} and \emph{false-positives}.

The used measures are
\begin{itemize}
    \item $\min$ and $\max$
    \item median and arithmetic mean
    \item variance and standard deviation
    \item skeweness
\end{itemize}

\subsubsection{Classification Evaluation}

The analysis of the keypoint and descriptor characteristics give already some insight into the algorithm performance but are not suitable for a comparison between different algorithms and do not give insight into potential trade-offs.
For this task the quality of the decisions the keypoint matching algorithm is required.
This is a common task in different scientific disciplines when using the classification formualation from above.
For a broad picture this evaluation uses multiple performance numbers.

\begin{itemize}
    \item precision
    \item recall or sensitivity
    \item fallout or false alarm rate
    \item accuracy or rand-index, as measure of correct decisions of the system
    \item youden-index as measure of informedness of the classifier
\end{itemize}

Each of these single measures gives insight into one aspect of decision making performance.
They do not give a systematic way to judge tradeoffs and no easy way to compare different configurations visually.

For this task, each configuration of an algorithm is plotted in \gls{ROC}-Space as a single point.
These plots make all provided configurations comparable and provide a simple way to judge the performance of a configuration.
