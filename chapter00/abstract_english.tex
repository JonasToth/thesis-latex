\begin{abstract}
\noindent
Features --- special identifiable bits of data --- and their recognition between different images play an important role in computer vision to solve tasks like visual odometry, place and object recognition or global localization.
Methods for these areas are established and implemented for common mobile devices and robots.
Even though depth data processing is omnipresent for robotic systems, feature detectors for salient, recognizable segments of such pointclouds are not an established method for reliable and robust localization without prior knowledge.

This work proposes depth image processing steps to utilize feature detectors and descriptors for color images on depth data.
In order to apply the algorithms SIFT, SURF, ORB and AKAZE on depth images, they are converted into derived feature images that encode the local geometry of the measured environment.
Multiple possible transformations of the depth data, from the already proposed Bearing-Angle image to measures of curvature and finally the novel Flexion image are developed, analyzed and evaluated with respect to, among other things, keypoint stability and discrimination potential of the descriptors.
The aspects keypoint count, size, response, the matching distance between true and false positives and additional measures like precision, recall and informedness are determined for four experimental datasets.
They consist of a synthetic scene, a underground mining environment, an office scene and LiDAR scans.
In addition, the impact of filtering the depth data with edge-preserving filters is analyzed on the outcome.

All experiments indicate a consistently better performance of the Flexion image compared to the Bearing-Angle image and proof that SIFT and AKAZE are suitable as feature detectors and descriptors whereas SURF and ORB are not.
This insight is underlined with the computation of a visual odometry benchmark.
The research forms a solid foundation to further develop the use of classical computer vision algorithms on Flexion images to accomplish feature-related tasks with depth data.
\end{abstract}
