\documentclass[doktyp=marbeit,fontsize=12pt,sprache=english,hausschrift=true,fleqn]{TUBAFarbeiten}

% packages
\usepackage{amsmath}
\usepackage[ngerman]{babel}
\usepackage{blindtext}
\usepackage{caption}
\usepackage{calc}
\usepackage{cite}
\usepackage{enumitem}
\usepackage[T1]{fontenc}
\usepackage{floatrow} % rows of table and pictures
\usepackage{graphicx}
\usepackage{gensymb}
\usepackage[utf8]{inputenc}
\usepackage{makeidx}
\usepackage[fleqn]{mathtools} % mathtools und links buendig machen
\usepackage{subcaption}
\usepackage{listings}
\usepackage{spreadtab}
\usepackage{pgfplots}
\usepackage{xcolor}

\definecolor{darkgreen}{RGB}{65,117,5}
\definecolor{darkred}{RGB}{208,2,27}

\definecolor{plotblue}{HTML}{4A90E2}
\definecolor{plotorange}{HTML}{F5A623}

\lstset{language=C++,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{green},
    stringstyle=\ttfamily\color{red!50!brown},
    basicstyle=\linespread{0.8}\ttfamily,
    numbers=left,
    stepnumber=1,
    showstringspaces=false}
\lstset{literate=%
   *{0}{{{\color{red!20!violet}0}}}1
    {1}{{{\color{red!20!violet}1}}}1
    {2}{{{\color{red!20!violet}2}}}1
    {3}{{{\color{red!20!violet}3}}}1
    {4}{{{\color{red!20!violet}4}}}1
    {5}{{{\color{red!20!violet}5}}}1
    {6}{{{\color{red!20!violet}6}}}1
    {7}{{{\color{red!20!violet}7}}}1
    {8}{{{\color{red!20!violet}8}}}1
    {9}{{{\color{red!20!violet}9}}}1
}

% Images with mathcha.io 
\usepackage{tikz}
\usetikzlibrary{fadings}
\usepackage{mathdots}
\usepackage{yhmath}
\usepackage{cancel}
\usepackage{color}
\usepackage{siunitx}
\usepackage{array}
\usepackage{multirow}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{tabularx}
\usepackage{booktabs}
% Images end


\usepackage{subscript} % tief stellen
%\usepackage[square]{natbib}
\usepackage{setspace}
\renewcommand{\baselinestretch}{1.5}

\usepackage{mathtools}
\input{commands}

\usepackage[acronym,toc]{glossaries}
\glstoctrue%

\newglossary[nlg]{symbols}{nls}{nlo}{Symbol Definition}
\makeglossaries%
\loadglsentries{chapter00/acronyms}
\loadglsentries{chapter00/definitions}
\loadglsentries{chapter00/symbols}

% tubaf zeugs
\input{thesis-meta}

\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}

% \makeindex

\usepackage[pdftex, unicode, hidelinks,
            pdfproducer={Latex with hyperref},
            pdfcreator={pdflatex}]{hyperref}
\hypersetup{colorlinks=false,
            citecolor=black,
            filecolor=black,
            linkcolor=black,
            urlcolor=black,
            linktoc=all}


% start the content
\begin{document}

\maketitle
\TUBAFErklaerungsseite%

\pagenumbering{roman}
\tableofcontents
\newpage

\input{chapter00/glossary}

\pagenumbering{arabic}
\newpage

\section{Introduction}
\input{chapter01/introduction}
\newpage

\section{Related Work}
\input{chapter02/related}
\newpage

\section{Fundamentals}

This section introduces the relevant principles used to create and evaluate the novel approach on depth data processing.

\input{chapter03/sensors}
\input{chapter03/coordinate_systems}
\input{chapter03/image_formation}
\input{chapter03/features}
\input{chapter03/statistics}
\newpage

\section{Depth Image Processing}

As with most sensor data the sensory input requires some preprocessing.
Error sources for depth sensors are absorption or reflexion of the infrared light, for example by water or glass.
Additionally each sensors has a range of sensing.
Every object too near or far can not be measured, sharp edges produce shadows.
Those conditions lead to missing distance values for such pixels, represented by zeros.

Another source of error are inaccurate measurements by the sensor.
Some sensors, like the Intel Realsense even have visible waves in the sensor output.
Additionally, depth images are discretized to integer precision.

These errors can be partially mitigated by preprocessing and filtering.

\input{chapter04/impainting}
\input{chapter04/filtering}
\input{chapter04/conversions}
\input{chapter04/features}
\newpage

\section{Experiments}

Experiments show the feature performance of the converted feature images with various state-of-the-art algorithms.
The provided data ranges from a synthetic scene, images taken by the kinectv2 and one high resolution LIDAR dataset.

Each dataset is processed with different filters and detection algorithm configurations.
Both the pinhole camera model and equirectangular model are used.

\input{chapter05/datasets}
\input{chapter05/metrics}
\input{chapter05/parameters}
\input{chapter05/odometry}
\newpage

\section{Results and Discussion}

Show the results for ROC curves.
Present histograms for size, response, distribution and descriptor distances.

\input{chapter06/algorithms}
\input{chapter06/detector}
\input{chapter06/descriptor}
\input{chapter06/error_discussion}
\newpage

\section{Conclusion}

Very Sensors dependent, Time-of-flight and Laserscan gives the best quality.
SURF does not perform well, Bearing Angle gives lower response and less stability
Flexion is very nice.
FAST based stuff does not perform well, more exotic descriptors neither.
SIFT best, AKAZE very good.
Approach to transform depth image first before processing further works and gives results.

\input{chapter07/future_work}
\newpage

\begin{appendix}
    % \clearpage
    \renewcommand*{\thepage}{\thesection\arabic{page}}
    \renewcommand{\thetable}{\thesection\arabic{table}}
    \renewcommand{\thefigure}{\thesection\arabic{figure}}

    % \input{anhang/content}
    \newpage

    \section{Wichtige Dinge}

    Hier stehen ganz wichtige Dinge.

    \newpage

    \addcontentsline{toc}{section}{References}
    \bibliographystyle{IEEEtran}
    \bibliography{references}

    \newpage
    \addcontentsline{toc}{section}{\listtablename}\listoftables

    \newpage
    \addcontentsline{toc}{section}{\listfigurename}\listoffigures

    \newpage
    %\renewcommand{\indexname}{Stichwortverzeichnis}
    %\addcontentsline{toc}{section}{Stichwortverzeichnis}
    % \printindex
\end{appendix}
\end{document}
